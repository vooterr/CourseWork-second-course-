import json
import os
import time
from tqdm import tqdm
from PIL import Image

# –ò–º–ø–æ—Ä—Ç—ã (—É–±–µ–¥–∏—Å—å, —á—Ç–æ –ø—É—Ç–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã)
from model.vlm.model import Florence2VLM, KosmosVLM, ModelConfig
from metrics.detection import Detection, match_boxes
from utils.visualizer import draw_and_save 

# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò ---
IMAGES_DIR = "data/coco/val2017"
ANNOTATION_FILE = "data/coco/annotations/instances_val2017.json"
OUTPUT_DIR = "predictions_vis"  # –ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å —Ä–∞–º–∫–∞–º–∏
LIMIT = 50                      # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–∞ (None = –≤—Å–µ)
SAVE_VISUALIZATION = True       # –†–∏—Å–æ–≤–∞—Ç—å –ª–∏ —Ä–∞–º–∫–∏

target = set()

def load_coco_data(json_path):
    """–ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ COCO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π"""
    print(f"üìÇ Loading annotations from {json_path}...")
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # –ú–∞–ø–ø–∏–Ω–≥–∏
    id_to_name = {c['id']: c['name'] for c in data['categories']}
    id_to_file = {i['id']: i['file_name'] for i in data['images']}
    
    # –°–±–æ—Ä–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
    dataset = []
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –ø–æ image_id —á–µ—Ä–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å
    img_anns = {}
    for ann in data['annotations']:
        if ann.get('iscrowd'): continue
        img_id = ann['image_id']
        if img_id not in img_anns: img_anns[img_id] = []
        
        # COCO [x,y,w,h] -> [x1,y1,x2,y2]
        x, y, w, h = ann['bbox']
        img_anns[img_id].append({
            "label": id_to_name[ann['category_id']],
            "bbox": [x, y, x + w, y + h]
        })
        target.add(id_to_name[ann['category_id']])

    for img_id, objs in img_anns.items():
        if img_id in id_to_file:
            dataset.append({"file_name": id_to_file[img_id], "objects": objs})
            
    return dataset, target

def main():
    # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    config = ModelConfig(device="auto", dtype="float16")
    model = Florence2VLM(config)

    model.load()
    
    # 2. –î–∞–Ω–Ω—ã–µ
    dataset, target = load_coco_data(ANNOTATION_FILE)
    if LIMIT: 
        dataset = dataset[:LIMIT]
        print(f"‚ö†Ô∏è Limit set: processing {LIMIT} images")

    # 3. –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª (–ò–Ω—Ñ–µ—Ä–µ–Ω—Å + –ú–µ—Ç—Ä–∏–∫–∏ + –í–∏–∑—É–∞–ª)
    total_tp, total_fp, total_fn = 0, 0, 0
    total_time = 0
    
    print(f"üöÄ Starting processing...")
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    target = ", ".join(list(target))
    prompt = f"<OPEN_VOCABULARY_DETECTION>"    
    for item in tqdm(dataset):
        img_path = os.path.join(IMAGES_DIR, item['file_name'])
        if not os.path.exists(img_path): continue

        try:
            image = Image.open(img_path).convert("RGB")
            gts = [Detection(o['label'], o['bbox']) for o in item['objects']]

            target = [o['label'] for o in item["objects"]]
            preds = []
            start = time.time()

            for tar in target:

            
                prompt_with_cls = f"{prompt}object: {tar}"
            # A. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
                start = time.time()
                detect = model.detect(image, prompt=prompt_with_cls)
                for dec in detect:
                    dec.label = dec.label.replace("object: ", "")
                preds += detect
            total_time += (time.time() - start)

            
            # B. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ GT
            gts = [Detection(o['label'], o['bbox']) for o in item['objects']]

            # C. –ú–µ—Ç—Ä–∏–∫–∏ (—Å—á–∏—Ç–∞–µ–º match –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞)
            tp, fp, fn = match_boxes(preds, gts, iou_threshold=0.5)
            
            total_tp += tp
            total_fp += fp
            total_fn += fn

            # D. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            if SAVE_VISUALIZATION:
                draw_and_save(image, gts, preds, item['file_name'], OUTPUT_DIR)

        except Exception as e:
            print(f"Error processing {item['file_name']}: {e}")

    # 4. –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    precision = total_tp / (total_tp + total_fp + 1e-6)
    recall = total_tp / (total_tp + total_fn + 1e-6)
    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)
    avg_time = total_time / len(dataset) if dataset else 0

    print("\n" + "="*30)
    print(f"üìä RESULTS on {len(dataset)} images:")
    print(f"Precision: {precision:.4f}")
    print(f"Recall:    {recall:.4f}")
    print(f"F1 Score:  {f1:.4f}")
    print(f"Avg Time:  {avg_time:.4f}s")
    print(f"Raw: TP={total_tp}, FP={total_fp}, FN={total_fn}")
    print(f"Visualizations saved to: {OUTPUT_DIR}")
    print("="*30)

if __name__ == "__main__":
    main()
